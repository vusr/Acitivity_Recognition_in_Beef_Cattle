{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31942ec-57fd-41cc-a42c-aa734c6fcc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the segmentation and classification models\n",
    "segmentation_model = YOLO('runs/segment/yolov8s_on_groundedsam_selected/weights/best.pt')\n",
    "classification_model = YOLO(\"runs/classify/train/weights/best.pt\")\n",
    "\n",
    "# Directories\n",
    "input_videos_dir = '../../DATA/Sampled_Test_Videos/'\n",
    "output_videos_dir = 'results/segmentation_classification_videos'\n",
    "os.makedirs(output_videos_dir, exist_ok=True)\n",
    "\n",
    "# Batch size for processing\n",
    "batch_size = 16\n",
    "\n",
    "# Function to process and classify objects\n",
    "def classify_objects(crops, model):\n",
    "    predictions = []\n",
    "    for batch_start in range(0, len(crops), batch_size):\n",
    "        batch = crops[batch_start:batch_start + batch_size]\n",
    "        predictions += model(batch, imgsz=224, verbose=False, device = 0)\n",
    "    return predictions\n",
    "\n",
    "# Process each video\n",
    "for video_name in os.listdir(input_videos_dir):\n",
    "    video_path = os.path.join(input_videos_dir, video_name)\n",
    "\n",
    "    # Open video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Define codec and create a VideoWriter\n",
    "    output_video_path = os.path.join(output_videos_dir, f\"output_{video_name}\")\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "    frames = []\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frames.append(frame)\n",
    "\n",
    "        # Process in batches\n",
    "        if len(frames) >= batch_size:\n",
    "            frames_batch = np.stack(frames)\n",
    "            results = segmentation_model(frames_batch, device=0, imgsz=(640, 640), verbose=False)\n",
    "\n",
    "            for i, result in enumerate(results):\n",
    "                frame = frames[i]\n",
    "                masks = result.masks\n",
    "                bboxes = result.boxes\n",
    "                crops = []\n",
    "\n",
    "                for mask, box in zip(masks, bboxes):\n",
    "                    x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                    crop = frame[y1:y2, x1:x2]\n",
    "                    if crop.size > 0:\n",
    "                        crops.append(crop)\n",
    "\n",
    "                # Classify crops\n",
    "                if crops:\n",
    "                    classifications = classify_objects(crops, classification_model)\n",
    "\n",
    "                    for cls_result, mask, box in zip(classifications, masks, bboxes):\n",
    "                        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                        pred_class = cls_result.probs.top1\n",
    "                        pred_label = classification_model.names[pred_class]\n",
    "                        pred_conf = cls_result.probs.top1conf.item()\n",
    "\n",
    "                        # Overlay bounding box, mask, and classification result\n",
    "                        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                        cv2.putText(frame, f\"{pred_label} ({pred_conf:.2f})\", (x1, y1 - 10),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "\n",
    "                # Save frame to output video\n",
    "                out.write(frame)\n",
    "\n",
    "            frames = []  # Clear batch\n",
    "\n",
    "    # Process remaining frames\n",
    "    if frames:\n",
    "        for frame in frames:\n",
    "            out.write(frame)\n",
    "\n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "print(\"All videos processed and saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
